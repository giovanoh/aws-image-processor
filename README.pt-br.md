# Processamento de Imagens com S3 + SQS + Lambda

> :globe_with_meridians: Leia em outros idiomas: [English](README.md)

## üìã √çndice
- [Vis√£o Geral](#vis√£o-geral)
- [Arquitetura](#arquitetura)
- [Pr√©-requisitos](#pr√©-requisitos)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Build do Projeto](#build-do-projeto)
- [Configura√ß√£o AWS Console](#configura√ß√£o-aws-console)
- [Testando o Sistema](#testando-o-sistema)
- [Troubleshooting](#troubleshooting)
- [Limpeza de Recursos](#limpeza-de-recursos-importante)
- [Pr√≥ximos Passos](#pr√≥ximos-passos)

---

## üéØ Vis√£o Geral

Este projeto demonstra uma arquitetura serverless completa na AWS para processamento autom√°tico de imagens. Quando uma imagem √© enviada ao S3, ela √© automaticamente processada (redimensionamento, otimiza√ß√£o) usando Lambda Functions.

### Funcionalidades
- Upload de imagens para S3
- Processamento ass√≠ncrono via Lambda
- Gera√ß√£o autom√°tica de thumbnails
- Retry autom√°tico em caso de falha (via SQS)
- Dead Letter Queue (DLQ) para mensagens problem√°ticas
- Logs no CloudWatch

---

## üèóÔ∏è Arquitetura

### Fluxo de Dados
1. **Upload**: Usu√°rio faz upload de `foto.jpg` para bucket `image-processor-in`
2. **Evento**: S3 envia notifica√ß√£o para fila SQS `product-image-queue`
3. **Trigger**: Lambda √© acionada automaticamente pelo SQS
4. **Processamento**: Lambda baixa imagem, cria thumbnail e vers√µes otimizadas
5. **Resultado**: Lambda salva imagens processadas no bucket `image-processor-out`
6. **Retry**: Se falhar, SQS retenta automaticamente (at√© 3 vezes)
7. **DLQ**: Mensagens que falharam 3x v√£o para `product-image-queue-dlq`

### Diagrama Detalhado

![Diagrama de Fluxo Completo](docs/Image%20Processor%20-%20Fluxo%20Completo.svg)

### Diagrama de Tratamento de Erros

Para um diagrama de sequ√™ncia detalhado mostrando o tratamento de erros e mecanismo de retry, veja: [Diagrama de Fluxo de Erro](docs/Image%20Processor%20-%20Fluxo%20com%20Erro%20e%20Retry.svg)

---

## üì¶ Pr√©-requisitos

### Ferramentas Necess√°rias
- Go (Golang) ([Instala√ß√£o](https://go.dev/doc/install))
- AWS CLI ([Instala√ß√£o](https://aws.amazon.com/cli/))
- Conta AWS (Free Tier funciona!)

### Configurar AWS CLI
```bash
# Configurar credenciais
aws configure
# AWS Access Key ID: AKIAIOSFODNN7EXAMPLE
# AWS Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# Default region name: us-east-1
# Default output format: json

# Testar
aws s3 ls
```

---

## üìÅ Estrutura do Projeto

```
aws-image-processor/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ lambda/
‚îÇ       ‚îî‚îÄ‚îÄ main.go                    # Ponto de entrada da fun√ß√£o Lambda
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ aws/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ s3_client.go               # Cliente para opera√ß√µes S3
‚îÇ   ‚îî‚îÄ‚îÄ processor/
‚îÇ       ‚îî‚îÄ‚îÄ image_processor.go         # L√≥gica principal de processamento de imagens
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ build.sh                       # Script de build
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture-flow.puml         # Diagrama da arquitetura em PlantUML
‚îÇ   ‚îî‚îÄ‚îÄ architecture-flow-error.puml   # Diagrama de fluxo de erro
‚îú‚îÄ‚îÄ go.mod                             # Depend√™ncias do projeto Go
‚îú‚îÄ‚îÄ go.sum                             # Checksum das depend√™ncias
‚îú‚îÄ‚îÄ .gitignore                         # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ README.md                          # Documenta√ß√£o do projeto em ingl√™s
‚îî‚îÄ‚îÄ README.pt-br.md                    # Documenta√ß√£o do projeto em portugu√™s
```

---

## üî® Build do Projeto

Antes de configurar os recursos AWS, √© necess√°rio fazer o build da fun√ß√£o Lambda. Este projeto inclui um script de build que automatiza todo o processo.

### Usando o Script de Build

O script de build (`scripts/build.sh`) vai:
1. Compilar o c√≥digo Go para Linux (necess√°rio para Lambda)
2. Criar um arquivo ZIP com o bin√°rio compilado
3. Deixar o artefato `lambda.zip` na raiz do projeto

**Para fazer o build do projeto:**

```bash
# Tornar o script execut√°vel (apenas na primeira vez)
chmod +x scripts/build.sh

# Executar o script de build
./scripts/build.sh
```

**Ap√≥s executar o script:**
- O arquivo `lambda.zip` ser√° criado na raiz do projeto
- Este arquivo ZIP √© o artefato que voc√™ vai fazer upload para o AWS Lambda (veja Passo 3 em Configura√ß√£o AWS Console)

**Pr√©-requisitos para o build:**
- Go deve estar instalado
- O utilit√°rio `zip` deve estar instalado (instale com: `sudo apt install zip unzip` no Ubuntu/Debian)

---

## üñ•Ô∏è Configura√ß√£o AWS Console

### Passo 1: Criar Buckets S3

> **üìù Nota:** Nomes de buckets S3 devem ser √∫nicos globalmente. Adicione seu nome, iniciais ou n√∫mero aleat√≥rio.

#### 1. Acessar S3 Console
   - Ir para: https://console.aws.amazon.com/s3/
   - Clicar em "Create bucket"

#### 2. Criar Bucket de Origem (Imagens Originais)

**Configura√ß√£o:**
   - **Bucket name:** `image-processor-in-{seu-nome}` (ex: `image-processor-in-giovano`)
   - **Region:** `us-east-1` (ou sua prefer√™ncia)
   - **Block Public Access:**
     - ‚úÖ Manter bloqueado (recomendado para seguran√ßa)
   - **Versioning:** Enabled (opcional, mas recomendado)
   - Clicar em "Create bucket"

#### 3. Criar Bucket de Destino (Imagens Processadas)

**Configura√ß√£o:**
   - **Bucket name:** `image-processor-out-{seu-nome}` (ex: `image-processor-out-giovano`)
   - **Region:** Mesma regi√£o do bucket de origem (`us-east-1`)
   - **Block Public Access:**
     - ‚ö†Ô∏è Desmarcar se quiser servir thumbnails publicamente
     - ‚úÖ OU manter bloqueado e usar CloudFront depois
   - Clicar em "Create bucket"

**üìå Buckets Criados:**
```
‚úÖ Bucket de Origem:  image-processor-in-{seu-nome}
‚úÖ Bucket de Destino: image-processor-out-{seu-nome}
```

### Passo 2: Criar Fila SQS

#### 1. Acessar SQS Console
   - Ir para: https://console.aws.amazon.com/sqs/
   - Clicar em "Create queue"

#### 2. Configurar Fila Principal

**Configura√ß√£o:**
   - **Name:** `product-image-queue`
   - **Type:** Standard
   - **Configuration:**
     - Visibility timeout: `300 seconds` (5 min)
     - Message retention period: `86400 seconds` (1 dia)
     - Receive message wait time: `20 seconds` (long polling)
   - **Dead-letter queue:** (configurar depois de criar a DLQ)
   - Clicar em "Create queue"

#### 3. Criar Dead Letter Queue (DLQ)

**Configura√ß√£o:**
   - **Name:** `product-image-queue-dlq`
   - **Type:** Standard
   - **Configuration:** Usar padr√µes
   - Clicar em "Create queue"

#### 4. Configurar DLQ na Fila Principal

   - Voltar para fila `product-image-queue`
   - Clicar em "Edit"
   - Na se√ß√£o **Dead-letter queue:**
     - ‚úÖ Enabled
     - Choose existing queue: `product-image-queue-dlq`
     - Maximum receives: `3`
   - Clicar em "Save"

**üìå Filas Criadas:**
```
‚úÖ Fila Principal: product-image-queue
‚úÖ Dead Letter Queue: product-image-queue-dlq
```

### Passo 3: Criar Fun√ß√£o Lambda

1. **Acessar Lambda Console**
   - Ir para: https://console.aws.amazon.com/lambda/
   - Clicar em "Create function"

2. **Configura√ß√£o B√°sica**
   - Option: **Author from scratch**
   - Function name: `ProcessImageFunction`
   - Runtime: **Amazon Linux 2023** (custom runtime)
   - Architecture: **x86_64**
   - Clicar em "Create function"

   > **‚ö†Ô∏è Importante:** Use "provided.al2023" com bin√°rio customizado.

3. **Upload do C√≥digo**
   - Na se√ß√£o "Code source"
   - Clicar em "Upload from" ‚Üí ".zip file"
   - Selecionar `lambda.zip` (bin√°rio compilado)
   - Clicar em "Save"

4. **Configurar Handler**
   - Na se√ß√£o "Runtime settings" ‚Üí Edit
   - Handler: `bootstrap`

   > **üí° Explica√ß√£o:** Para custom runtime, o execut√°vel DEVE se chamar "bootstrap".

5. **Configura√ß√µes da Fun√ß√£o**
   - **General configuration** ‚Üí Edit:
     - Memory: `512 MB`
     - Timeout: `1 min`
     - Ephemeral storage: `512 MB`

   - **Environment variables** ‚Üí Edit ‚Üí Add environment variable:
     ```
     Key:   OUTPUT_BUCKET
     Value: image-processor-out-{seu-nome}
     ```

6. **Configurar Permiss√µes (IAM Role)**
   - Na aba "Configuration" ‚Üí "Permissions"
   - Clicar no Role name (vai abrir IAM console)
   - "Add permissions" ‚Üí "Attach policies"
   - Adicionar:
     - ‚úÖ `AmazonS3FullAccess`
     - ‚úÖ `AWSLambdaSQSQueueExecutionRole`
     - ‚úÖ `CloudWatchLogsFullAccess`

### Passo 4: Conectar S3 ‚Üí SQS

#### 1. Configurar Permiss√µes SQS

Antes de criar o event notification, o S3 precisa ter permiss√£o para enviar mensagens para a fila:

1. Ir para **SQS Console**
2. Selecionar fila `product-image-queue`
3. Aba **"Access policy"** ‚Üí **Edit**
4. **Substituir** todo o conte√∫do pela pol√≠tica abaixo:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "s3.amazonaws.com"
      },
      "Action": "sqs:SendMessage",
      "Resource": "arn:aws:sqs:us-east-1:SEU-ACCOUNT-ID:product-image-queue",
      "Condition": {
        "ArnEquals": {
          "aws:SourceArn": "arn:aws:s3:::image-processor-in-{seu-nome}"
        }
      }
    }
  ]
}
```

5. **Substituir `SEU-ACCOUNT-ID`** pelo seu Account ID (12 d√≠gitos)
6. Clicar em **Save**

> **üí° Como descobrir seu Account ID:**
>
> **Op√ß√£o 1 - Console AWS:**
> - Clicar no seu nome no canto superior direito
> - Aparece o n√∫mero de 12 d√≠gitos
>
> **Op√ß√£o 2 - AWS CLI:**
> ```bash
> aws sts get-caller-identity --query Account --output text
> ```

#### 2. Acessar Bucket S3

   - Ir para bucket `image-processor-in-{seu-nome}`
   - Aba "Properties"

#### 3. Event Notifications

   - Descer at√© "Event notifications"
   - Clicar em "Create event notification"

#### 4. Configurar Evento

**Configura√ß√£o:**
   - **Event name:** `ImageUploadedEvent`
   - **Prefix:** *(deixe vazio para processar todas as imagens)*
   - **Suffix:** `.jpg` (opcional - apenas JPGs, ou deixe vazio para todos os tipos)
   - **Event types:**
     - ‚úÖ `s3:ObjectCreated:Put`
     - ‚úÖ `s3:ObjectCreated:Post`
     - ‚úÖ `s3:ObjectCreated:CompleteMultipartUpload`
   - **Destination:** SQS queue
   - **SQS queue:** `product-image-queue`
   - Clicar em **"Save changes"**

**‚úÖ Se tudo estiver correto, voc√™ ver√° uma mensagem de sucesso!**

### Passo 5: Conectar SQS ‚Üí Lambda

#### 1. Acessar Lambda Function
   - Fun√ß√£o: `ProcessImageFunction`

#### 2. Adicionar Trigger

   - Clicar em "Add trigger"
   - **Select a source:** SQS
   - **SQS queue:** `product-image-queue`
   - **Batch size:** `10` (processa at√© 10 mensagens por vez)
   - **Batch window:** `5` seconds (opcional)
   - Expandir **"Additional settings"**:
     - ‚úÖ **Report batch item failures** (IMPORTANTE!)
   - ‚úÖ **Enable trigger**
   - Clicar em "Add"

#### 3. Verificar Configura√ß√£o

   - Na p√°gina da Lambda, deve aparecer o diagrama:
   ```
   SQS (product-image-queue) ‚Üí Lambda (ProcessImageFunction)
   ```

**üìå Fluxo Completo Configurado:**
```
S3 (image-processor-in-{seu-nome})
   ‚Üì evento
SQS (product-image-queue)
   ‚Üì trigger
Lambda (ProcessImageFunction)
   ‚Üì output
S3 (image-processor-out-{seu-nome})
```

---

## üß™ Testando o Sistema

### 1. Teste Manual via AWS CLI

```bash
# Upload de uma imagem de teste
aws s3 cp test-image.jpg s3://image-processor-in-{seu-nome}/test-image.jpg

# Verificar mensagens na fila
aws sqs get-queue-attributes \
    --queue-url https://sqs.us-east-1.amazonaws.com/ACCOUNT-ID/product-image-queue \
    --attribute-names ApproximateNumberOfMessages

# Ver logs da Lambda
aws logs tail /aws/lambda/ProcessImageFunction --follow

# Verificar resultado no bucket de sa√≠da
aws s3 ls s3://image-processor-out-{seu-nome}/ --recursive

# Ver thumbnails criados
aws s3 ls s3://image-processor-out-{seu-nome}/thumbnails/
aws s3 ls s3://image-processor-out-{seu-nome}/medium/
```

### 2. Teste via Console Web

**Upload via Console S3:**
1. Ir para bucket `image-processor-in-{seu-nome}`
2. Clicar em "Upload"
3. Arrastar uma imagem JPG
4. Clicar em "Upload"
5. Aguardar processamento (~5-10 segundos)
6. Verificar bucket `image-processor-out-{seu-nome}`
7. Deve ter pastas `thumbnails/` e `medium/` com as imagens processadas

### 3. Monitoramento no CloudWatch

```bash
# Ver logs em tempo real
aws logs tail /aws/lambda/ProcessImageFunction --follow --format short

# Buscar erros
aws logs filter-pattern "ERROR" \
    --log-group-name /aws/lambda/ProcessImageFunction \
    --start-time $(date -u -d '10 minutes ago' +%s)000

# M√©tricas
aws cloudwatch get-metric-statistics \
    --namespace AWS/Lambda \
    --metric-name Invocations \
    --dimensions Name=FunctionName,Value=ProcessImageFunction \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Sum
```

---

## üßπ Limpeza de Recursos

### Por que Limpar?

Alguns recursos AWS geram custos mesmo quando n√£o est√£o em uso:
- **S3:** Cobra por armazenamento (GB/m√™s)
- **Lambda:** Geralmente gr√°tis se n√£o invocar
- **SQS:** Geralmente gr√°tis no Free Tier
- **CloudWatch Logs:** Cobra por armazenamento de logs

### Ordem Correta de Remo√ß√£o

√â importante seguir a ordem para evitar erros de depend√™ncia:

```
1. Desabilitar Triggers e Event Notifications
2. Deletar Lambda Function
3. Deletar Filas SQS
4. Esvaziar e Deletar Buckets S3
5. Deletar IAM Roles e Policies (opcional)
6. Deletar CloudWatch Log Groups
```

---

## üöÄ Pr√≥ximos Passos

### Infrastructure as Code (IaC) com Terraform

Atualmente, este projeto requer configura√ß√£o manual atrav√©s do Console AWS. Como pr√≥ximo passo, pode ser implementado Infrastructure as Code (IaC) usando Terraform para provisionar todos os recursos AWS diretamente.

---

**‚≠ê Se este projeto foi √∫til, considere dar uma estrela no GitHub!**
